from abc import ABC, abstractmethod
from typing import Tuple, Dict, Optional
from PIL import Image
import numpy as np
import cv2
from lookup import AbstractAPIManager


class SatelliteImageProceeder:
    def __init__(self, api_manager: AbstractAPIManager,
                 forest_place: Dict = None,
                 field_place: Dict = None,
                 road_place: Dict = None):
        """
        api_manager: –æ–±'—î–∫—Ç, —â–æ —Ä–µ–∞–ª—ñ–∑—É—î AbstractAPIManager
        forest_place, field_place, road_place: —Å–ª–æ–≤–Ω–∏–∫–∏ —Ñ–æ—Ä–º–∞—Ç—É
            {"name_of_place": name, "location": {"lat":..., "lng":...}}

        –Ø–∫—â–æ –Ω–µ –≤–∫–∞–∑–∞–Ω—ñ ‚Äî –±—É–¥—É—Ç—å –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –¥–µ—Ñ–æ–ª—Ç–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏.
        –ü—ñ–¥ —á–∞—Å —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó –≤–∏–∫–ª–∏–∫–∞—é—Ç—å—Å—è api_manager.find_photo(place_dict)
        –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–æ—ó –∑–æ–Ω–∏, —ñ –≤–∏–∑–Ω–∞—á–∞—é—Ç—å—Å—è HSV-–¥—ñ–∞–ø–∞–∑–æ–Ω–∏.
        """
        self.api = api_manager

        # --- –î–µ—Ñ–æ–ª—Ç–Ω—ñ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∏ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω–∏—Ö –∑–æ–Ω (–º–æ–∂–Ω–∞ –∑–∞–º—ñ–Ω–∏—Ç–∏ —Å–≤–æ—ó–º–∏)
        if forest_place is None:
            forest_place = {"name_of_place": "forest_sample", "location": {"lat": 51.2220, "lng": 30.8930}}  # –ª—ñ—Å
        if field_place is None:
            field_place = {"name_of_place": "field_sample", "location": {"lat": 49.1280, "lng": 31.9100}}   # –ø–æ–ª–µ
        if road_place is None:
            road_place = {"name_of_place": "road_sample", "location": {"lat": 50.4501, "lng": 30.5234}}     # –¥–æ—Ä–æ–≥–∞

        print("üîé Requesting calibration images using API.find_photo(...)")
        f_img = self.api.find_photo(forest_place)
        fe_img = self.api.find_photo(field_place)
        r_img = self.api.find_photo(road_place)
        
        f_img = self._get_central_fraction(f_img)
        fe_img = self._get_central_fraction(fe_img)
        r_img = self._get_central_fraction(r_img)
        
        f_img.save("forest_full.png")
        fe_img.save("field_full.png")
        r_img.save("road_full.png")

        if f_img is None or fe_img is None or r_img is None:
            raise RuntimeError("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –≤—Å—ñ –∫–∞–ª—ñ–±—Ä—É–≤–∞–ª—å–Ω—ñ –∑–Ω—ñ–º–∫–∏ (forest/field/road).")

        # --- –ö–∞–ª—ñ–±—Ä—É–≤–∞–Ω–Ω—è HSV –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ç–∏–ø—É –º—ñ—Å—Ü–µ–≤–æ—Å—Ç—ñ ---
        self.hsv_ranges = {
            "trees": self._analyze_hsv_range(f_img),
            "fields": self._analyze_hsv_range(fe_img),
            "roads": self._analyze_hsv_range(r_img),
        }

        print("‚úÖ Calibration completed. HSV ranges:")
        for k, (low, high) in self.hsv_ranges.items():
            print(f"  {k}: low={low.tolist()}, high={high.tolist()}")

    # ----------------------------------------------------------------------
    # –ê–Ω–∞–ª—ñ–∑ HSV –¥—ñ–∞–ø–∞–∑–æ–Ω—ñ–≤
    # ----------------------------------------------------------------------
    def _analyze_hsv_range(self, image_pil: Image.Image) -> Tuple[np.ndarray, np.ndarray]:
        """–ü–æ–≤–µ—Ä—Ç–∞—î (low, high) –º–∞—Å–∏–≤–∏ uint8 –¥–ª—è cv2.inRange (H,S,V)."""
        img_cv = cv2.cvtColor(np.array(image_pil.convert("RGB")), cv2.COLOR_RGB2BGR)
        hsv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2HSV)
        h, s, v = hsv[:, :, 0].ravel(), hsv[:, :, 1].ravel(), hsv[:, :, 2].ravel()

        # –Ü–≥–Ω–æ—Ä—É—î–º–æ "–º–µ—Ä—Ç–≤—ñ" –ø—ñ–∫—Å–µ–ª—ñ –∑ V<15
        valid_mask = v > 15
        h, s, v = h[valid_mask], s[valid_mask], v[valid_mask]

        if len(h) == 0:
            print("‚ö†Ô∏è Warning: Empty or grayscale image detected.")
            return np.array([0, 0, 0], dtype=np.uint8), np.array([179, 255, 255], dtype=np.uint8)

        # –í–∏–∫–ª—é—á–∞—î–º–æ –µ–∫—Å—Ç—Ä–µ–º–∞–ª—å–Ω—ñ —à—É–º–∏ ‚Äî 5-–π —ñ 95-–π –ø–µ—Ä—Ü–µ–Ω—Ç–∏–ª—ñ
        low = np.array([np.percentile(h, 5), np.percentile(s, 5), np.percentile(v, 5)], dtype=np.uint8)
        high = np.array([np.percentile(h, 95), np.percentile(s, 95), np.percentile(v, 95)], dtype=np.uint8)

        # –†–æ–∑—à–∏—Ä—é–≤–∞–ª—å–Ω–∞ "–ø–æ–¥—É—à–∫–∞", —â–æ–± –Ω–µ –≤—Ç—Ä–∞—Ç–∏—Ç–∏ —á–∞—Å—Ç–∏–Ω—É –≤—ñ–¥—Ç—ñ–Ω–∫—ñ–≤
        pad = np.array([3, 10, 10], dtype=np.uint8)
        low = np.clip(low - pad, 0, 255)
        high = np.clip(high + pad, 0, 255)

        return low, high
    
    def _get_central_fraction(self, image_pil: Image.Image, fraction: float = 0.1) -> Image.Image:
        if not (0 < fraction <= 1):
            raise ValueError("fraction –º–∞—î –±—É—Ç–∏ –≤ –º–µ–∂–∞—Ö (0, 1].")

        # –ì–∞—Ä–∞–Ω—Ç–æ–≤–∞–Ω–æ RGB, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –≤—Ç—Ä–∞—Ç–∏ –∫–æ–ª—å–æ—Ä—É
        image_pil = image_pil.convert("RGB")

        img_cv = np.array(image_pil)
        h, w = img_cv.shape[:2]

        crop_h = max(1, int(h * fraction))
        crop_w = max(1, int(w * fraction))

        y0 = h // 2 - crop_h // 2
        x0 = w // 2 - crop_w // 2

        cropped = img_cv[y0:y0 + crop_h, x0:x0 + crop_w]

        # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –∑–Ω–æ–≤—É —è–∫ RGB
        return Image.fromarray(cropped, mode="RGB")


    def process_satellite_image(self, image_pil: Image.Image, cols: int = 2, rows: int = 2,
                                debug: bool = False) -> Image.Image:
        """
        –†–æ–∑–±–∏–≤–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–∞ tiles, —Ñ—ñ–ª—å—Ç—Ä—É—î –∑–∞ HSV —ñ –Ω–∞–∫–ª–∞–¥–∞—î –∫–æ–ª—å–æ—Ä–æ–≤—ñ –º–∞—Å–∫–∏.
        - –õ—ñ—Å (trees): —Å–∏–Ω—ñ–π
        - –ü–æ–ª—è (fields): —á–µ—Ä–≤–æ–Ω–∏–π
        - –î–æ—Ä–æ–≥–∏ (roads): –∂–æ–≤—Ç–∏–π
        """
        img_cv = cv2.cvtColor(np.array(image_pil.convert("RGB")), cv2.COLOR_RGB2BGR)
        height, width = img_cv.shape[:2]
        tile_w, tile_h = width // cols, height // rows
        processed_tiles = []

        # –†–æ–∑–ø–∞–∫–æ–≤—É—î–º–æ HSV –¥—ñ–∞–ø–∞–∑–æ–Ω–∏
        low_trees, high_trees = self.hsv_ranges["trees"]
        low_fields, high_fields = self.hsv_ranges["fields"]
        low_roads, high_roads = self.hsv_ranges["roads"]

        for y in range(rows):
            row_tiles = []
            for x in range(cols):
                x0, y0 = x * tile_w, y * tile_h
                x1, y1 = x0 + tile_w, y0 + tile_h
                tile = img_cv[y0:y1, x0:x1]

                # MeanShift —Ñ—ñ–ª—å—Ç—Ä–∞—Ü—ñ—è –¥–ª—è –∑–º–µ–Ω—à–µ–Ω–Ω—è —à—É–º—É
                shifted = cv2.pyrMeanShiftFiltering(tile, 5, 20)
                hsv = cv2.cvtColor(shifted, cv2.COLOR_BGR2HSV)

                # –ú–∞—Å–∫–∏
                mask_trees = cv2.inRange(hsv, low_trees, high_trees)
                mask_fields = cv2.inRange(hsv, low_fields, high_fields)
                mask_roads = cv2.inRange(hsv, low_roads, high_roads)

                # –ó–≥–ª–∞–¥–∂—É–≤–∞–Ω–Ω—è
                mask_trees = cv2.GaussianBlur(mask_trees, (7, 7), 0)
                mask_fields = cv2.GaussianBlur(mask_fields, (7, 7), 0)
                mask_roads = cv2.GaussianBlur(mask_roads, (7, 7), 0)

                if debug:
                    print(f"Tile ({x},{y}): trees={np.count_nonzero(mask_trees)}, "
                          f"fields={np.count_nonzero(mask_fields)}, roads={np.count_nonzero(mask_roads)}")

                # –ù–∞–∫–ª–∞–¥–∞–Ω–Ω—è –∫–æ–ª—å–æ—Ä—ñ–≤
                color_overlay = tile.copy()
                color_overlay[mask_roads > 0]  = (0, 255, 255)
                color_overlay[mask_trees > 0]  = (255, 0, 0)
                color_overlay[mask_fields > 0] = (0, 0, 255)


                blended = cv2.addWeighted(tile, 0.8, color_overlay, 0.2, 0)
                row_tiles.append(blended)

            processed_row = np.hstack(row_tiles)
            processed_tiles.append(processed_row)

        combined = np.vstack(processed_tiles)
        return Image.fromarray(cv2.cvtColor(combined, cv2.COLOR_BGR2RGB))

    # ----------------------------------------------------------------------
    # –û—Ç—Ä–∏–º–∞–Ω–Ω—è –∑–Ω—ñ–º–∫—É –∑–∞ –Ω–∞–∑–≤–æ—é –º—ñ—Å—Ü—è (—á–µ—Ä–µ–∑ API)
    # ----------------------------------------------------------------------
    def process_by_place(self, place_name: str, cols=2, rows=2, debug=False) -> Image.Image:
        """–û—Ç—Ä–∏–º—É—î —Å—É–ø—É—Ç–Ω–∏–∫–æ–≤–µ —Ñ–æ—Ç–æ –¥–ª—è –º—ñ—Å—Ü—è —á–µ—Ä–µ–∑ API —ñ –æ–±—Ä–æ–±–ª—è—î –π–æ–≥–æ."""
        photo = self.api.get_photo_by_place(place_name)
        if not photo:
            raise ValueError(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –¥–ª—è '{place_name}'")
        return self.process_satellite_image(photo, cols, rows, debug)

    # ----------------------------------------------------------------------
    # –ü–æ–≤–µ—Ä—Ç–∞—î –∑–Ω–∞–π–¥–µ–Ω—ñ HSV-–¥—ñ–∞–ø–∞–∑–æ–Ω–∏
    # ----------------------------------------------------------------------
    def get_hsv_ranges(self) -> Dict[str, Tuple[np.ndarray, np.ndarray]]:
        return self.hsv_ranges
